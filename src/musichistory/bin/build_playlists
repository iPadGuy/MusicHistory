#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# build_playlists - Tuesday, November 22, 2022
""" This replaces top_daily_lists, builds weekly, monthly, and yearly lists """
__version__ = "0.11.41-dev1"

import click, coloredlogs, logging, os, pendulum, shutil, sys, time
import sqlalchemy as sa
import logging.config
import oyaml as yaml

# from datetime import datetime, timedelta, timezone
from dateutil.parser import parse, ParserError
from dateutil.relativedelta import relativedelta
from glob import glob
from os.path import (
	basename,
	exists,
	expanduser,
	getmtime,
	getsize,
	join,
	lexists,
	realpath,
)
from pathlib import Path
from sqlalchemy import create_engine
from time import sleep
from xdg_base_dirs import xdg_config_home

appname = "MusicHistory"
basedir = os.path.dirname(os.path.dirname(__file__))
config_dir = xdg_config_home()
if not config_dir:
	config_dir = os.path.expanduser("~/.config")
if appname:
	config_dir = os.path.join(config_dir, appname)
try:
	sys.path.insert(0, config_dir)
except ModuleNotFoundError:
	raise ModuleNotFoundError("config.py")
from config import Config  # noqa

__MODULE__ = Path(__file__).resolve().stem


@click.command()
@click.argument("list_date", default="today")
@click.option(
	"-f",
	"--force/--no-force",
	is_flag=True,
	default=True,
	help="Force playlists to be written (overwrite)",
)
def main(list_date, force):
	fn_logger.debug(f"List Date: {list_date}")
	yesterday = pendulum.yesterday().date()
	if list_date.lower() in ["today", "yesterday"]:
		list_date = yesterday
	# elif list_date.lower() == "rebuild":
	# 	rebuild()
	else:
		try:
			list_date = parse(list_date).date()
		except ParserError as e:
			fn_logger.exception(e)
			raise
	if list_date > _run_dt.date():
		raise ValueError("Future dates aren't processed.")
	fn_logger.debug(f"Processing music history for {list_date}")
	build_top_lists(list_date, force)
	if list_date == yesterday:
		build_recent_lists(list_date)
		# 2025-Apr-11 PAL - Disabling this during transition to new dt_playhistory
		# build_dusty_lists(list_date)
	return


def init():
	fn_logger.debug(
		f"{__MODULE__} v{__version__} Run Start: {_run_dt.format(_datefmt)}"
	)
	if not exists(_playlist_dir):
		for d in "daily weekly monthly quarterly yearly".split():
			os.makedirs(join(_playlist_dir, d))
	return


def eoj():
	# fn_logger = logging.getLogger(__MODULE__ + ".eoj")
	# Create symlinks in Music folder
	# make_aliases()
	stop_dt = pendulum.now()
	duration = stop_dt - _run_dt
	fn_logger.debug(
		f"Run Stop: {stop_dt.format(_datefmt)}  Duration: {duration.as_timedelta()}"
	)
	return


def do_nothing():
	pass


def build_query(db_column: str) -> str:
	# fn_logger = logging.getLogger(__MODULE__ + ".build_query")
	cols = ", ".join(
		[
			"ROW_NUMBER() OVER(ORDER BY count(*) DESC, sum(play_secs) DESC) AS rownum",
			"count(*) playcount",
			"sum(play_secs) AS total_play_secs",
			"dpt.filename",
		]
	)

	frm = " ".join(
		[
			f"{_table_name} dpt",
			"INNER JOIN dim_date dd",
			"ON dpt.playdate = dd.date_id",
		]
	)
	ands = [
		f"dd.{db_column} = :list_date",
		"dpt.play_secs > :min_play_secs",
		"dpt.filename LIKE :file_prefix",
		"dpt.filename NOT LIKE :christmas_prefix",
	]
	whr = " AND ".join(ands)
	grp = "dpt.filename HAVING count(*) > 1"
	ordr = "playcount DESC"

	query = "\n".join(
		[
			f"SELECT {cols}",
			f"FROM {frm}",
			f"WHERE {whr}",
			f"GROUP BY {grp}",
			f"ORDER BY {ordr}",
			f"LIMIT :list_size;",
		]
	)
	return query


def build_dusty_lists(list_date: pendulum.date) -> None:
	"""
	Builds playlist for songs that haven't been played in a while
	"""
	fn_logger.info('Generating playlist(s) for "dusty" items . . .')
	os.chdir(_music_dir)
	# playlist_dir = Path(".Playlists3")

	# Set parameters for database query
	list_type = "dusty"
	list_sizes = [25, 40, 100]
	for list_size in list_sizes:
		list_name = f"{list_type.capitalize()}{list_size}"
		playlist_filename = _playlist_dir / f"{list_name}.m3u"
		linkname = playlist_filename.name
		fn_logger.debug(f"Generating '{playlist_filename.name}'")
		params = {
			"list_size": int(list_size * 1.25),  # Allow for missing files
		}
		sql = "SELECT filename FROM dusty_30 ORDER BY random() LIMIT :list_size;"
		playlist = []
		missing = []
		with engine.connect() as conn:
			result = conn.execute(sa.text(sql), params)
			fn_logger.info(
				f"{list_type.capitalize()} {list_size}: Row count: {result.rowcount}"
			)
			# Only generate playlists if there are enough items
			if result.rowcount < list_size * 0.8:
				fn_logger.warning(
					f"Not enough items to generate playlist '{list_name}'"
				)
				raise Warning(f"Not enough items to generate playlist '{list_name}'")
			# Add filenames to playlist
			for i, row in enumerate(result.fetchall()):
				fname = row[0]
				msg = f"{i+1:3d}) {basename(fname)}"
				if exists(fname):
					playlist.append(fname)
				else:
					msg += " (Not Found)"
					missing.append(fname)
				fn_logger.debug(msg)
			# Truncate playlist to desired size
			playlist = playlist[:list_size]

			# Timestamp for playlist
			mtime = date_to_timestamp(list_date, end_of_day=True)
			# mtime = datetime.combine(list_date, datetime.max.time()).timestamp()
			if exists(playlist_filename):
				old_playlist_mtime = playlist_filename.stat().st_mtime
			else:
				old_playlist_mtime = -1
			if mtime > old_playlist_mtime:
				fn_logger.info(f"Writing playlist to '{playlist_filename}'")
				os.makedirs(os.path.dirname(playlist_filename), exist_ok=True)
				with open(playlist_filename, "wt") as pfile:
					pfile.writelines([x + "\n" for x in playlist])
				sleep(0.1)
				# Set mtime to list_date
				os.utime(playlist_filename, times=(mtime, mtime))
				# Create symlink in Music folder
				make_symlink(
					playlist_filename, linkname, overwrite=True, times=(mtime, mtime)
				)
		if missing:
			missing_count = len(missing)
			missing_filename = _playlist_dir / "NotFound.m3u"
			linkname = missing_filename.name
			if exists(missing_filename):
				with open(missing_filename, "r") as mfile_in:
					missing.extend([x.rstrip() for x in mfile_in.readlines()])
				sleep(0.1)
			missing = sorted(list(set(missing)))
			total_missing_count = len(missing)
			fn_logger.warning(
				f"Adding {missing_count} file(s) to '{missing_filename.name}' (Total: {total_missing_count})"
			)
			with open(missing_filename, "wt") as mfile_out:
				mfile_out.writelines([x + "\n" for x in missing])
			sleep(0.1)
			# Set mtime to list_date
			os.utime(missing_filename, times=(mtime, mtime))
			# Create symlink in Music folder
			make_symlink(
				missing_filename, linkname, overwrite=True, times=(mtime, mtime)
			)
	return


def build_recent_lists(list_date: pendulum.date) -> None:
	"""
	Builds playlist for the last 25 songs played
	"""
	# fn_logger = logging.getLogger(__MODULE__ + ".build_recent_lists")
	fn_logger.info("Generating playlist(s) for recent items . . .")
	os.chdir(_music_dir)
	# playlist_dir = Path(".Playlists3")

	# Set parameters for database query
	file_prefix = expanduser("~/Music/%")
	list_size = 25
	list_type = "last"
	list_name = f"{list_type.capitalize()}{list_size}"
	min_play_secs = 30
	playlist_filename = _playlist_dir / f"{list_name}.m3u"
	linkname = playlist_filename.name
	fn_logger.debug(f"Generating '{playlist_filename.name}'")
	# yesterday = (_run_dt - timedelta(days=1)).date()
	query_date = list_date - relativedelta(days=3)
	params = {
		"query_date": query_date,
		"list_size": list_size,
		"file_prefix": file_prefix,
		"min_play_secs": min_play_secs,
	}
	sql = """
		SELECT filename
		FROM (
			SELECT filename, max(playdatetime) last_played
			FROM dt_playhistory dp
			WHERE filename LIKE :file_prefix
			  AND play_secs > :min_play_secs
			  AND playdate >= :query_date
			GROUP BY filename
			ORDER BY filename
			LIMIT 1000
		) a
		ORDER BY last_played DESC
		LIMIT :list_size;
	"""
	playlist = []
	with engine.connect() as conn:
		result = conn.execute(sa.text(sql), params)
		fn_logger.info(
			f"{list_type.capitalize()} {list_size}: Row count: {result.rowcount}"
		)
		# Only generate playlists if there are enough items
		if result.rowcount < list_size * 0.8:
			fn_logger.warning(f"Not enough items to generate playlist '{list_name}'")
			raise Warning(f"Not enough items to generate playlist '{list_name}'")
		# new_playlist_mtime = (datetime.fromisoformat(yesterday.isoformat())
		#                      + timedelta(hours=23, minutes=59, seconds=59, microseconds=999999)
		#                      ).timestamp()
		# Add filenames to playlist
		for i, row in enumerate(result.fetchall()):
			filename = row[0]
			fn_logger.debug(f"{i+1:3d}) {basename(filename)}")
			playlist.append(filename)

	# Timestamp for playlist
	mtime = date_to_timestamp(list_date, end_of_day=True)
	# mtime = datetime.combine(list_date, datetime.max.time()).timestamp()
	if exists(playlist_filename):
		old_playlist_mtime = playlist_filename.stat().st_mtime
	else:
		old_playlist_mtime = -1
	if mtime > old_playlist_mtime:
		fn_logger.info(f"Writing playlist to '{playlist_filename}'")
		os.makedirs(os.path.dirname(playlist_filename), exist_ok=True)
		with open(playlist_filename, "wt") as pfile:
			pfile.writelines([x + "\n" for x in playlist])
		sleep(0.1)
		# Set mtime to list_date
		os.utime(playlist_filename, times=(mtime, mtime))
		# Create symlink in Music folder
		make_symlink(playlist_filename, linkname, overwrite=True, times=(mtime, mtime))
	return


def build_top_lists(list_date: pendulum.date, force: bool) -> None:
	# fn_logger = logging.getLogger(__MODULE__ + ".build_top_lists")
	playlists = which_lists(list_date, force)
	os.chdir(_music_dir)
	# playlist_dir = Path(".Playlists3")
	if playlists:
		# Set parameter for database query
		file_prefix = expanduser("~/Music/%")
		min_play_secs = 30
		for list_type in playlists.keys():
			fn_logger.debug(f"{list_date}: {list_type:7s} {playlists[list_type]}")
			db_column = playlists[list_type]
			christmas_prefix = expanduser("~/Music/Christmas/%")
			if list_type == "daily":
				list_size = 10
				list_name = list_date.strftime("%A")
			elif list_type == "weekly":
				list_size = 40
				list_name = list_date.strftime("%Y-W%U")
				if list_date.month == 12:
					christmas_prefix = ""
			elif list_type == "monthly":
				list_size = 100
				list_name = list_date.strftime("%Y-%m-%B")
				if list_date.month == 12:
					christmas_prefix = ""
			elif list_type == "quarterly":
				list_size = 250
				quarter = int(list_date.month / 3)
				prev_date = list_date - relativedelta(months=3)
				prev_quarter = int(prev_date.month / 3)
				list_name = list_date.strftime(f"%Y-Q{quarter}")
			elif list_type == "yearly":
				list_size = 500
				list_name = list_date.strftime("%Y")
			else:
				raise ValueError(f"Uknown list type: {list_type}")
			if list_date.month == 12 and list_date.day < 31:
				christmas_prefix = ""
			params = {
				f"list_date": list_date,
				"list_size": list_size,
				"file_prefix": file_prefix,
				"christmas_prefix": christmas_prefix,
				"min_play_secs": min_play_secs,
			}
			# fn_logger.info(f"Parameters: {params}")
			sql = build_query(db_column)
			# fn_logger.info(f"SQL: {sql}")
			playlist = []
			# Get play history from database
			with engine.connect() as conn:
				result = conn.execute(sa.text(sql), params)
				fn_logger.info(
					f"{list_type.capitalize()} for {list_date}: Row count: {result.rowcount}"
				)
				# Only generate playlists if there are enough items
				if result.rowcount < list_size * 0.8:
					fn_logger.warning(
						f"Not enough items to generate playlist '{list_name}'"
					)
					continue
				for row_number, playcount, playsecs, filename in result.fetchall():
					fn_logger.debug(
						f"{row_number:3d}) {playcount:3d} {playsecs:9.2f} {basename(filename)}"
					)
					playlist.append(filename)

			# Make Playlist
			filename = _playlist_dir / list_type / f"{list_name}_Top{list_size}.m3u"
			linkname = filename.name
			# ToDo: need linknames for previous list and "ly" alias (at least alias)
			prev_filename = find_prev_filename(list_date, _playlist_dir / list_type)
			# prev_filename = playlist_dir / list_type / f"{prev_name}_Top{list_size}.m3u"
			aliasname = f"{list_type.capitalize()}.m3u"
			prev_aliasname = f"Prev_{aliasname}"
			fn_logger.debug(f"Generating '{filename.name}'")
			make_playlist(filename, list_date, playlist, force)
			# Timestamp for playlist
			mtime = date_to_timestamp(list_date, end_of_day=True)
			# mtime = datetime.combine(list_date, datetime.max.time()).timestamp()
			for alias in [linkname, aliasname, prev_aliasname]:
				if alias == prev_aliasname:
					src = prev_filename
				else:
					src = filename
				if src:
					make_symlink(src, alias, overwrite=True, times=(mtime, mtime))

			# Make Countdown Playlist
			filename = (
				_playlist_dir / list_type / f"{list_name}_Top{list_size}_Countdown.m3u"
			)
			linkname = filename.name
			prev_filename = find_prev_filename(
				list_date, _playlist_dir / list_type, countdown=True
			)
			aliasname = f"{list_type.capitalize()}_Countdown.m3u"
			prev_aliasname = f"Prev_{aliasname}"
			fn_logger.debug(f"Generating '{filename.name}'")
			make_playlist(filename, list_date, list(reversed(playlist)), force)
			for alias in [linkname, aliasname, prev_aliasname]:
				if alias == prev_aliasname:
					src = prev_filename
				else:
					src = filename
				make_symlink(src, alias, overwrite=True, times=(mtime, mtime))
	else:
		fn_logger.info(f"No playlists to generate for {list_date}")
	return


def date_to_timestamp(list_date: pendulum.date, end_of_day: bool = False) -> float:
	y, m, d = list_date.year, list_date.month, list_date.day
	dt = pendulum.datetime(y, m, d, tz="local")

	if end_of_day:
		dt = dt.end_of("day")
	ts = dt.timestamp()
	return ts


def do_backup(pathname: str | Path, max_backups: int = 10) -> str | None:
	# fn_logger = logging.getLogger(__MODULE__ + ".do_backup")
	backupname = None
	if not exists(pathname):
		fn_logger.error(f"File Not Found: {pathname}")
		raise FileNotFoundError(pathname)
	perform_backup = True
	mtime = getmtime(pathname)
	backups = glob(f"{pathname}~*")
	suffix = f"~"
	if backups:
		last_backup = max(backups, key=getmtime)
		if mtime > getmtime(last_backup):
			num = last_backup.split("~")[-1].rstrip(".").lstrip(".")
			if num == "":
				num = 0
			else:
				num = int(num)
			suffix = f"~.{num+1}"
		else:
			perform_backup = False
	if perform_backup:
		backupname = f"{pathname}{suffix}"
		fn_logger.debug(f"Backup: {backupname}")
		shutil.copy(pathname, backupname)
		os.utime(backupname, times=(mtime, mtime))
	return backupname


def find_prev_filename(
	list_date: pendulum.date, playlist_dir: str | Path, countdown: bool = False
) -> str | None:
	prev_list = None
	list_ts = date_to_timestamp(list_date)
	# list_ts = datetime.combine(list_date, datetime.min.time()).timestamp()
	if not countdown:
		playlists = [
			x
			for x in os.scandir(playlist_dir)
			if x.name.endswith("m3u")
			and "Countdown" not in x.name
			and getmtime(x.path) < list_ts
		]
	else:
		playlists = [
			x
			for x in os.scandir(playlist_dir)
			if x.name.endswith("m3u")
			and "Countdown" in x.name
			and getmtime(x.path) < list_ts
		]
	if playlists:
		prev_list = max(playlists, key=getmtime).path
		fn_logger.debug(f"Previous List: {prev_list}")
	return prev_list


def make_playlist(
	filename: str, list_date: pendulum.date, playlist: list | set, force: bool
) -> None:
	# Timestamp for playlist
	mtime = date_to_timestamp(list_date, end_of_day=True)
	# mtime = datetime.combine(list_date, datetime.max.time()).timestamp()
	backupname = None
	if exists(filename):
		if force:
			backupname = do_backup(filename)
			fn_logger.debug(f"Forcing new playlist, removing '{filename}'")
			os.remove(filename)
			do_nothing()
		elif mtime <= getmtime(filename):
			fn_logger.warning(f"File Exists: {filename}, skipping")
			# raise FileExistsError(filename)
			return
	fn_logger.info(f"Writing playlist to '{filename}'")
	os.makedirs(os.path.dirname(filename), exist_ok=True)
	with open(filename, "wt") as pfile:
		pfile.writelines([x + "\n" for x in playlist])
	sleep(0.1)
	# Set mtime to list_date
	os.utime(filename, times=(mtime, mtime))
	if force and backupname:
		if getsize(filename) == getsize(backupname):
			os.remove(backupname)
	return


def make_symlink(filename, linkname, overwrite=False, times=None):
	# fn_logger = logging.getLogger(__MODULE__ + ".make_symlink")
	if filename and linkname:
		msg = "Creating"
		# Remove symlink, if orphaned
		if not exists(filename) and lexists(linkname):
			os.unlink(linkname)
		elif lexists(linkname) and overwrite:
			# Only overwrite older linknames
			if realpath(filename) != realpath(linkname):
				if os.stat(filename).st_mtime > os.lstat(linkname).st_mtime:
					msg = "Updating"
					os.unlink(linkname)
		if not lexists(linkname):
			fn_logger.debug(f"{msg} symlink: {linkname}")
			os.symlink(filename, linkname)
			if times:
				os.utime(linkname, times=times, follow_symlinks=False)
	return


def which_lists(list_date: pendulum.date, force: bool) -> dict:
	playlists = dict()

	# sql = f"SELECT * FROM dim_date WHERE date_id = :list_date;"
	sql = f"SELECT * FROM dim_date WHERE date_id = :list_date LIMIT 1;"
	params = {"list_date": list_date}
	rows = None
	with engine.connect() as conn:
		results = conn.execute(sa.text(sql), params).fetchone()
		rows = dict(results._mapping)
		do_nothing()
	if rows:
		datediff = (_run_dt.date() - list_date).days
		if datediff <= 7 or force:
			# Only generate daily playlists for the last week
			playlists.update({"daily": "date_id"})
		for period in ["week", "month", "quarter", "year"]:
			if not force:
				if period == "week" and datediff > 100:
					fn_logger.warning(
						"Not generating weekly lists for dates more than three months ago"
					)
					continue
				elif period == "month" and datediff > 366:
					fn_logger.warning(
						"Not generating monthly lists for dates more than a year ago"
					)
					continue
			col = f"{period}_thru"
			if rows[col] == list_date:
				playlists.update({f"{period}ly": col})
	return playlists


def rebuild_old():
	yesterday = pendulum.yesterday().date()
	start_date = pendulum.date(2025, 1, 1)
	# end_date = pendulum.yesterday().date()
	# day_delta = timedelta(days=1)
	# start_date.add(days=1)
	os.chdir(_data_dir)
	for i in range(0, (yesterday - start_date).days + 1):
		list_date = start_date.add(days=i)
		fn_logger.debug(f"Processing music history for {list_date}")
		build_top_lists(list_date, force=True)
		if list_date == yesterday:
			build_recent_lists(list_date)
			# The views for Dusty lists aren't in new_media_library
			# build_dusty_lists(list_date)
	return


if __name__ == "__main__":
	_run_dt = pendulum.now()
	_run_utc = _run_dt.astimezone(pendulum.timezone("UTC"))
	# _datefmt = "YYYY-MM-DD HH:mm:ss.SSSSSSZZ zz z"
	_datefmt = "YYYY-MM-DD HH:mm:ss.SSSSSSZZ"
	# _run_dt = pendulum.now().astimezone().replace(microsecond=0)
	# _run_utc = _run_dt.astimezone(timezone.utc).replace(tzinfo=None)
	_fdate = _run_dt.strftime("%Y-%m-%d")
	_fdatetime = _run_dt.strftime("%Y%m%d_%H%M%S")

	# Configure Directories
	_data_dir = Config.DATA_DIR
	_music_dir = Config.MUSIC_DIR
	_playlist_dir = Config.PLAYLIST_DIR
	_table_name = Config.TABLE_NAME

	# Configure List Types
	_list_types = Config.LIST_TYPES

	# Configure Logging
	with open(join(config_dir, "logging.yaml"), "r") as f:
		log_cfg = yaml.safe_load(f.read())
	logging.config.dictConfig(log_cfg)
	coloredlogs.install(fmt=log_cfg["formatters"]["simple"]["format"])
	logger = logging.getLogger("")
	logger.setLevel(logging.DEBUG)
	fn_logger = logging.getLogger(__MODULE__)

	# Configure Database
	engine = create_engine(Config.DATABASE_URL)
	schema = Config.DB_SCHEMA

	# SET PosgreSQL search_path
	@sa.event.listens_for(engine, "connect", insert=True)
	def set_search_path(dbapi_connection, connection_record):
		sql = f"SET SESSION search_path TO {schema},public;"
		existing_autocommit = dbapi_connection.autocommit
		dbapi_connection.autocommit = True
		cursor = dbapi_connection.cursor()
		cursor.execute(sql)
		cursor.close()
		dbapi_connection.autocommit = existing_autocommit

	init()
	# Ref: https://stackoverflow.com/a/55758208/2719754
	main(standalone_mode=False)
	eoj()
