#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# build_top_lists - Tuesday, November 22, 2022
""" This replaces top_daily_lists, builds weekly, monthly, and yearly lists """
__version__ = "0.6.22-dev0"

import click, coloredlogs, logging, os, sys
import sqlalchemy as sa
import logging.config
import oyaml as yaml
from datetime import datetime, timedelta, timezone
from dateutil.parser import parse, ParserError
from glob import glob
from os.path import basename, exists, expanduser, getmtime, join, lexists, realpath
from pathlib import Path
from sqlalchemy import create_engine
from time import sleep
from xdg import XDG_CONFIG_HOME

appname = "MusicHistory"
basedir = os.path.dirname(os.path.dirname(__file__))
config_dir = XDG_CONFIG_HOME
if not config_dir:
    config_dir = os.path.expanduser("~/.config")
if appname:
    config_dir = os.path.join(config_dir, appname)
try:
    sys.path.insert(0, config_dir)
except ModuleNotFoundError:
    raise ModuleNotFoundError("config.py")
from config import Config  # noqa

__MODULE__ = Path(__file__).resolve().stem


@click.command()
@click.argument("list_date", default="today")
def main(list_date):
    fn_logger = logging.getLogger(__MODULE__ + ".main")

    fn_logger.info(f"List Date: {list_date}")
    if list_date.lower() == "today":
        list_date = (_run_dt - timedelta(days=1)).date()
    else:
        try:
            list_date = parse(list_date).date()
        except ParserError as e:
            fn_logger.exception(e)
            raise
    fn_logger.debug(f"Processing music history for {list_date}")
    build_lists(list_date)
    return


def init():
    fn_logger = logging.getLogger(__MODULE__ + ".init")
    fn_logger.info(f"{__MODULE__} v{__version__} Run Start: {_run_dt}")
    return


def eoj():
    fn_logger = logging.getLogger(__MODULE__ + ".eoj")
    # Create symlinks in Music folder
    make_aliases()
    stop_dt = datetime.now().astimezone().replace(microsecond=0)
    duration = stop_dt.replace(microsecond=0) - _run_dt.replace(microsecond=0)
    fn_logger.info(f"Run Stop: {stop_dt}  Duration: {duration}")
    return


def build_query(db_column: str) -> str:
    fn_logger = logging.getLogger(__MODULE__ + ".build_query")
    cols = ", ".join(["ROW_NUMBER() OVER(ORDER BY count(*) DESC) rownum",
                      "count(*) playcount",
                      "dpt.filename",
    ])

    frm = " ".join([f"{tablename} dpt",
                    "INNER JOIN dim_date dd",
                    "ON dpt.playdate = dd.date_id",
    ])
    ands = [f"dd.{db_column} = :list_date",
            "dpt.play_secs > 3",
            "dpt.filename LIKE :file_prefix",
            ]
    whr = " AND ".join(ands)
    grp = "dpt.filename HAVING count(*) > 1"
    ordr = "playcount DESC"

    query = "\n".join([f"SELECT {cols}",
                       f"FROM {frm}",
                       f"WHERE {whr}",
                       f"GROUP BY {grp}",
                       f"ORDER BY {ordr}",
                       f"LIMIT :list_size;",
                       ])
    return query


def build_lists(list_date: datetime.date) -> None:
    fn_logger = logging.getLogger(__MODULE__ + ".build_lists")
    playlists = which_lists(list_date)
    os.chdir(_music_dir)
    playlist_dir = Path(".Playlists")
    if playlists:
        # Set parameter for database query
        file_prefix = expanduser("~/Music/%")
        for list_type in playlists.keys():
            fn_logger.info(f"{list_date}: {list_type:7s} {playlists[list_type]}")
            db_column = playlists[list_type]
            if list_type == "daily":
                list_size = 10
                list_name = list_date.strftime("%A")
            elif list_type == "weekly":
                list_size = 40
                list_name = list_date.strftime("%Y-W%U")
            elif list_type == "monthly":
                list_size = 100
                list_name = list_date.strftime("%Y-%m-%B")
            elif list_type == "quarterly":
                list_size = 250
                quarter = int(list_date.month / 3)
                list_name = list_date.strftime(f"%Y-Q{quarter}")
            elif list_type == "yearly":
                list_size = 500
                list_name = list_date.strftime("%Y")
            else:
                raise ValueError(f"Uknown list type: {list_type}")
            playlist_filename = playlist_dir / list_type / f"Top{list_size}_{list_name}.m3u"
            linkname = playlist_filename.name
            fn_logger.info(f"Generating '{playlist_filename.name}'")
            params = {f"list_date": list_date, "list_size": list_size, "file_prefix": file_prefix}
            # fn_logger.info(f"Parameters: {params}")
            sql = build_query(db_column)
            # fn_logger.info(f"SQL: {sql}")
            playlist = []
            # Get play history from database
            with engine.connect() as conn:
                result = conn.execute(sa.text(sql), params)
                fn_logger.info(f"{list_type.capitalize()} for {list_date}: Row count: {result.rowcount}")
                # Only generate playlists if there are enough items
                if result.rowcount < list_size - 2:
                    fn_logger.warning(f"Not enough items to generate playlist '{list_name}'")
                    continue
                # Timestamp for playlist
                new_playlist_mtime = (datetime.fromisoformat(list_date.isoformat())
                                      + timedelta(hours=23, minutes=59, seconds=59, milliseconds=999)
                                      ).timestamp()
                # Add filenames to playlist
                for row_number, playcount, filename in result.fetchall():
                    fn_logger.info(f"{row_number:3d}) {playcount:3d} {filename}")
                    playlist.append(filename)
            if exists(playlist_filename):
                if new_playlist_mtime <= playlist_filename.stat().st_mtime:
                    fn_logger.warning(f"File Exists: {playlist_filename}, skipping")
                    continue
            fn_logger.info(f"Writing playlist to '{playlist_filename}'")
            os.makedirs(os.path.dirname(playlist_filename), exist_ok=True)
            with open(playlist_filename, "w") as pfile:
                pfile.writelines([x+"\n" for x in playlist])
            sleep(0.1)
            # Set mtime to list_date
            times = (new_playlist_mtime, new_playlist_mtime)
            os.utime(playlist_filename, times=times)
            # Create symlink in Music folder
            make_symlink(playlist_filename, linkname, overwrite=True, times=times)
    else:
        fn_logger.info(f"No playlists to generate for {list_date}")
    return


def make_aliases():
    fn_logger = logging.getLogger(__MODULE__ + ".make_aliases")
    # Change to Music directory in order to have relative symlinks to playlists
    os.chdir(_music_dir)
    playlist_dir = Path(".Playlists")
    for list_type in _list_types:
        list_dir = playlist_dir / list_type
        # print(f"List Dir: {list_dir}")
        playlists = [x for x in glob(join(list_dir, "*.m3u"), recursive=False) if "YTD" not in x]
        playlists = sorted(playlists, key=getmtime)
        for playlist in playlists[-2:]:
            listname = basename(playlist)
            prefix = listname.split("_")[0]
            if playlist == playlists[-2]:
                prefix = f"Prev_{prefix}"
            # Relative to current directory (set to ~/Music, above)
            linkname = f"{prefix}_{list_type.capitalize()}.m3u"
            mtime = getmtime(playlist)
            """if lexists(linkname):
                if mtime > getmtime(linkname):
                    fn_logger.info(f"Removing symlink: {linkname}")
                    os.unlink(linkname)
                else:
                    continue"""
            make_symlink(playlist, linkname, overwrite=True, times=(mtime, mtime))
    return


def make_symlink(filename, linkname, overwrite=False, times=None):
    fn_logger = logging.getLogger(__MODULE__ + ".make_symlink")
    msg = "Creating"
    # Only overwrite older linknames
    if exists(linkname) and overwrite:
        if realpath(filename) != realpath(linkname):
            if getmtime(filename) > getmtime(linkname):
                msg = "Updating"
                os.unlink(linkname)
    if not lexists(linkname):
        fn_logger.info(f"{msg} symlink: {linkname}")
        os.symlink(filename, linkname)
        if times:
            os.utime(linkname, times=times, follow_symlinks=False)
    return


def which_lists(list_date: datetime.date) -> dict:
    playlists = dict()

    sql = f"SELECT * FROM dim_date WHERE date_id = :list_date;"
    params = {"list_date": list_date}
    rows = None
    with engine.connect() as conn:
        rows = dict(conn.execute(sa.text(sql),  params).fetchone())
    if rows:
        datediff = (_run_dt.date() - list_date).days
        if datediff <= 7:
            # Only generate daily playlists for the last week
            playlists.update({"daily": "date_id"})
        for period in ["week", "month", "quarter", "year"]:
            if period == "week" and datediff > 100:
                fn_logger.warning("Not generating weekly lists for dates more than three months ago")
                continue
            elif period == "month" and datediff > 366:
                fn_logger.warning("Not generating monthly lists for dates more than a year ago")
                continue
            col = f"{period}_thru"
            if rows[col] == list_date:
                playlists.update({f"{period}ly": col})
    return playlists


def do_nothing():
    pass


if __name__ == '__main__':
    _run_dt = datetime.now().astimezone().replace(microsecond=0)
    _run_utc = _run_dt.astimezone(timezone.utc).replace(tzinfo=None)
    _fdate = _run_dt.strftime("%Y-%m-%d")
    _fdatetime = _run_dt.strftime("%Y%m%d_%H%M%S")

    # Configure Directories
    _data_dir = Config.DATA_DIR
    _music_dir = Config.MUSIC_DIR
    # _playlist_dir = Config.PLAYLIST_DIR
    tablename = Config.TABLE_NAME

    # Configure List Types
    _list_types = Config.LIST_TYPES

    # Configure Logging
    with open(join(basedir, "logging.yaml"), 'r') as f:
        log_cfg = yaml.safe_load(f.read())
    logging.config.dictConfig(log_cfg)
    coloredlogs.install(fmt=log_cfg['formatters']['simple']['format'])
    logger = logging.getLogger("")
    logger.setLevel(logging.DEBUG)
    fn_logger = logging.getLogger(__MODULE__)

    # Configure Database
    engine = create_engine(Config.DATABASE_URL)
    schema = Config.DB_SCHEMA

    @sa.event.listens_for(engine, "connect", insert=True)
    def set_search_path(dbapi_connection, connection_record):
        sql = f"SET SESSION search_path TO {schema},public;"
        existing_autocommit = dbapi_connection.autocommit
        dbapi_connection.autocommit = True
        cursor = dbapi_connection.cursor()
        cursor.execute(sql)
        cursor.close()
        dbapi_connection.autocommit = existing_autocommit

    init()
    # Ref: https://stackoverflow.com/a/55758208/2719754
    main(standalone_mode=False)
    eoj()
